{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6519f30f",
   "metadata": {},
   "source": [
    "# GANS/Cyclic GANS For Data Augmentation and Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9dccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import random\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# Model class\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "# Layers\n",
    "from tensorflow.keras.layers import (LeakyReLU, BatchNormalization, Dropout, \n",
    "                                     Flatten, Conv2D, Dense, MaxPool2D, Conv2DTranspose, \n",
    "                                     GlobalMaxPool2D, Reshape, BatchNormalization, Input, Embedding, multiply)\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Loss function\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanAbsoluteError \n",
    "\n",
    "# Data loader\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# Metrics\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Recall, Precision, MSE\n",
    "\n",
    "# ImageLoader\n",
    "from skimage.io import imread\n",
    "\n",
    "# Weights Initializer\n",
    "from tensorflow.keras.initializers import RandomNormal, GlorotNormal, GlorotUniform\n",
    "\n",
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "# Initializers\n",
    "from tensorflow.keras.initializers import RandomNormal, RandomUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a843a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4828027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To limit GPU VRAM allocation by tensorflow\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e83de3",
   "metadata": {},
   "source": [
    "## Pre-Processing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Sequence):\n",
    "    \n",
    "    def __init__(self, im_dir, labels= None, batch_size= 32, output_dim= None, classification= True, shuffle= True):\n",
    "        \n",
    "        self.im_dir = im_dir\n",
    "        self.classification = classification\n",
    "        self.shuffle = shuffle\n",
    "        self.resize = resize\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.labels = {}\n",
    "        if isinstance(labels, list):\n",
    "            for i, label in enumerate(labels):\n",
    "                self.labels[label] = i\n",
    "        elif isinstance(labels, dict):\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            for root_dir, subdirs, files in os.walk(self.im_dir):\n",
    "                for i, subdir in enumerate(subdirs):\n",
    "                    self.labels[subdir] = i\n",
    "        \n",
    "            \n",
    "        self.images = glob.glob(f\"{self.im_dir}/*/*\")\n",
    "        random.shuffle(self.images)\n",
    "        self.batch_size = len(self.images) if batch_size == -1 else batch_size\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.images)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        im_files_batch = [self.images[idx] for idx in indexes]\n",
    "        if self.output_dim:\n",
    "            batch_images = np.array([resize(imread(file), self.output_dim, preserve_range= True) for file in im_files_batch], dtype= np.uint8)\n",
    "            \n",
    "        else:\n",
    "            batch_images = np.arrary([imread(file) for file in im_files_batch], dtype= np.uint8)\n",
    "        \n",
    "        if self.classification:\n",
    "            batch_images = np.asanyarray(batch_images, dtype= np.float32)/255.\n",
    "        else:\n",
    "            batch_images = (np.asanyarray(batch_images, dtype= np.float32) - 127.5)/127.5\n",
    "            \n",
    "        batch_labels = np.empty((self.batch_size), dtype= np.uint8)\n",
    "        for i, im in enumerate(im_files_batch):\n",
    "            for label in self.labels.keys():\n",
    "                if label in im:\n",
    "                    batch_labels[i] = self.labels[label]\n",
    "        return batch_images, batch_labels.reshape(-1, 1)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"Updates all indexes after the end of each epoch\"\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "        \n",
    "    def get_all_data(self, batched_data):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71036ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_horses_cows = DataLoader(im_dir= \"dataset/Newdata/Train\", classification= True, output_dim= (128, 128, 3), batch_size= 16)\n",
    "val_horses_cows = DataLoader(im_dir= \"dataset/Newdata/Test\", classification= True, output_dim= (128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a327579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "horses_cows_iter = iter(train_horses_cows)\n",
    "batch_data = next(horses_cows_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d32dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_batch = [data for i, data in enumerate(batch_data[0]) if batch_data[1][i] == 1]\n",
    "cow_batch = [data for i, data in enumerate(batch_data[0]) if batch_data[1][i] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_horse = np.random.choice(range(len(horse_batch)), size= 4, replace= False)\n",
    "random_cow = np.random.choice(range(len(cow_batch)-1), size= 4, replace= False)\n",
    "random_horse, random_cow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cow_images, horse_images = [cow_batch[i] for i in random_cow], [horse_batch[i] for i in random_horse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74460f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 10.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, [*cow_images, *horse_images]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab1109",
   "metadata": {},
   "source": [
    "## Define Metrics For Classification\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics_classification(model_history):\n",
    "    metrics = [\"_\".join(metric.split(\"_\")[1:]) for metric in model_history.history.keys() if \"val\" not in metric]\n",
    "    print(metrics)\n",
    "    colors = list(itertools.combinations(['b', 'g', 'r', 'c', 'm', 'y', 'k'], 2))\n",
    "    \n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(2.5*len(metrics))\n",
    "    f.set_figheight(3*len(metrics))\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(math.ceil(len(metrics)/2), 2, i+1)\n",
    "        color_plts = np.random.randint(0, len(colors))\n",
    "        plt.plot(model_history.history[f\"train_{metric}\"], color= colors[color_plts][0])\n",
    "        plt.plot(model_history.history[f\"val_{metric}\"], color= colors[color_plts][1])\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.legend([\"train\", \"val\"], loc= \"upper left\")\n",
    "        plt.title(f\"{metric.title()} vs Epochs\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da16a602",
   "metadata": {},
   "source": [
    "## Building The Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(Model):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super(Classifier, self).__init__(name= name)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.conv1 = Conv2D(filters= 50, kernel_size= 3, activation= 'relu', padding= 'same', kernel_initializer= 'glorot_uniform', input_shape= input_shape)\n",
    "        self.maxpool1 = MaxPool2D(pool_size= (2, 2))\n",
    "        \n",
    "        self.conv2 = Conv2D(filters= 20, kernel_size= 3, activation= 'relu', padding= 'valid', kernel_initializer= 'glorot_uniform')\n",
    "        self.maxpool2 = MaxPool2D(pool_size= (2, 2))\n",
    "        \n",
    "        self.conv3 = Conv2D(filters= 5, kernel_size= 3, activation= 'relu', padding= 'valid', kernel_initializer= 'glorot_uniform')\n",
    "        self.maxpool3 = MaxPool2D(pool_size= (2, 2))\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(units= 30, activation= 'relu', kernel_initializer= 'glorot_uniform')\n",
    "        self.dense2 = Dense(units= 20, activation= 'relu', kernel_initializer= 'glorot_uniform')\n",
    "        self.dense3 = Dense(units= 1, activation= 'sigmoid', kernel_initializer= 'glorot_uniform')\n",
    "        \n",
    "        super(Classifier, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input_):\n",
    "        x = self.conv1(input_)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "     \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        output = self.dense3(x)\n",
    "        return output\n",
    "    \n",
    "    def train_step(self, train_batch):\n",
    "        X_train, y_train = train_batch\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # apply forward pass\n",
    "            y_pred = self(X_train, training= True)\n",
    "            loss = self.compiled_loss(y_train, y_pred, regularization_losses= self.losses)\n",
    "        # calculate gradients - uses reverse gradient autodiff\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        # backpropagate the gradients and update the weights using the compiled optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        self.compiled_metrics.update_state(y_train, y_pred)\n",
    "        return {f\"train_{metric.name}\": metric.result() for metric in self.metrics}\n",
    "    \n",
    "    def test_step(self, test_batch):\n",
    "        X_test, y_test = test_batch\n",
    "        # obtain prediciton\n",
    "        y_pred = self(X_test, training= False)\n",
    "        \n",
    "        # updates loss metric\n",
    "        self.compiled_loss(y_test, y_pred)\n",
    "        \n",
    "        # updates metrics\n",
    "        self.compiled_metrics.update_state(y_test, y_pred)\n",
    "        \n",
    "        return {f\"{metric.name}\": metric.result() for metric in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3308f0",
   "metadata": {},
   "source": [
    "## Traning the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS= 50\n",
    "BATCH_SIZE= 16\n",
    "IMAGE_SIZE= (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a42c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses_cows_classification = DataLoader(im_dir= \"dataset/Newdata/Train\", classification= True, output_dim= IMAGE_SIZE, batch_size= BATCH_SIZE)\n",
    "val_horses_cows_classification = DataLoader(im_dir= \"dataset/Newdata/Test\", classification= True, output_dim= IMAGE_SIZE, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "horses_cows_classifier = Classifier(name= \"Horses_vs_Cows_Classifier\")\n",
    "horses_cows_classifier.build(input_shape= (None, *IMAGE_SIZE))\n",
    "\n",
    "horses_cows_classifier.summary()\n",
    "horses_cows_classifier.compile(optimizer= Adam(0.001), loss= BinaryCrossentropy(), metrics= [BinaryAccuracy(), Recall(), Precision(), MSE])\n",
    "model_data = horses_cows_classifier.fit(train_horses_cows_classification, validation_data= val_horses_cows_classification, epochs= EPOCHS, workers= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7149dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics_classification(horses_cows_classifier.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9138f2",
   "metadata": {},
   "source": [
    "## DC-GAN\n",
    "First, we will experiment with a normal DCGAN without conditioning the output to a desired target variable. This way we gain more understanding of how GANs train which can be carried to the Conditional GAN part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a8185",
   "metadata": {},
   "source": [
    "### Building The DCGAN Architecture\n",
    "#### Generator\n",
    "#### Convolutional Layer With Batch Normalization and Leaky ReLU Activation Function\n",
    "This block will be used multiple times in the Generator Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82eb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTBatchNorm(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, use_bias):\n",
    "        super(Conv2DTBatchNorm, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.use_bias = use_bias\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.conv2d_t = Conv2DTranspose(filters= self.filters, kernel_size= self.kernel_size, strides= self.strides, use_bias= self.use_bias)\n",
    "        self.batch_norm = BatchNormalization()\n",
    "        self.leaky_relu = LeakyReLU()\n",
    "        super(Conv2DTBatchNorm, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        x = input_tensor\n",
    "        \n",
    "        x = self.conv2d_t(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        \n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebb5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self, latent_dim, name, **kwargs):\n",
    "        super(Generator, self).__init__(name= name, **kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert input_shape[1:] == (1, 1, self.latent_dim), f\"input_shape should have shape (batch_size, 1, 1, latent_dimension), received: {input_shape}\"\n",
    "        self.conv2d_t_1 = Conv2DTBatchNorm(filters= 64*12, kernel_size= (4, 4), strides=(1, 1), padding=\"valid\", use_bias= False)\n",
    "        self.conv2d_t_2 = Conv2DTBatchNorm(filters= 64*8, kernel_size= (2, 2), strides=(2, 2), padding=\"same\", use_bias= False)\n",
    "        self.conv2d_t_3 = Conv2DTBatchNorm(filters= 64*8, kernel_size= (2, 2), strides=(2, 2), padding=\"same\", use_bias= False)\n",
    "        self.conv2d_t_4 = Conv2DTBatchNorm(filters= 64*4, kernel_size= (2, 2), strides=(2, 2), padding=\"same\", use_bias= False)\n",
    "        self.conv2d_t_5 = Conv2DTBatchNorm(filters= 64*4, kernel_size= (2, 2), strides=(2, 2), padding=\"same\", use_bias= False)\n",
    "        self.conv2d_t_6 = Conv2DTBatchNorm(filters= 64*2, kernel_size= (2, 2), strides=(2, 2), padding=\"same\", use_bias= False)\n",
    "        \n",
    "        self.conv2d = Conv2D(filters= 3, kernel_size= (3, 3), strides=(1, 1), padding=\"same\", use_bias= False, activation= \"tanh\")\n",
    "        super(Generator, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        x = input_tensor\n",
    "        x = self.conv2d_t_1(x)\n",
    "        x = self.conv2d_t_2(x)\n",
    "        x = self.conv2d_t_3(x)\n",
    "        x = self.conv2d_t_4(x)\n",
    "        x = self.conv2d_t_5(x)\n",
    "        x = self.conv2d_t_6(x)\n",
    "        \n",
    "        x = self.conv2d(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84549266",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DBatchNorm(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, padding, use_bias, batch_norm= True):\n",
    "        super(Conv2DBatchNorm, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.use_bias = use_bias\n",
    "        self.batch_norm = batch_norm\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.conv = Conv2D(filters= self.filters, kernel_size= self.kernel_size, strides= self.strides, padding= self.padding, use_bias= self.use_bias)\n",
    "        if self.batch_norm:\n",
    "            self.bn = BatchNormalization()\n",
    "        self.leaky_relu = LeakyReLU(alpha= 0.2)\n",
    "        \n",
    "        super(Conv2DBatchNorm, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        x = input_tensor\n",
    "        x = self.conv(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.bn(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4919c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self, name, **kwargs):\n",
    "        super(Discriminator, self).__init__(name, **kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = Conv2DBatchNorm(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)\n",
    "        \n",
    "        self.conv_bn_1 = Conv2DBatchNorm(filters=64*2, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)\n",
    "        self.conv_bn_2 = Conv2DBatchNorm(filters=64*4, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)        \n",
    "        self.conv_bn_3 = Conv2DBatchNorm(filters=64*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)        \n",
    "        self.conv_bn_4 = Conv2DBatchNorm(filters=64*8, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)        \n",
    "        self.conv_bn_5 = Conv2DBatchNorm(filters=64*4, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)        \n",
    "        self.conv_bn_6 = Conv2DBatchNorm(filters=64*2, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)\n",
    "        self.conv_bn_7 = Conv2DBatchNorm(filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False, batch_norm= False)  \n",
    "        \n",
    "        self.conv2 = Conv2D(1, (3, 3), strides=(4, 4), padding=\"same\", use_bias= False, activation= 'sigmoid')\n",
    "        super(Discriminator, self).build(input_shape)\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        x = input_tensor\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.conv_bn_1(x)\n",
    "        x = self.conv_bn_2(x)\n",
    "        x = self.conv_bn_3(x)\n",
    "        x = self.conv_bn_4(x)\n",
    "        x = self.conv_bn_5(x)        \n",
    "        x = self.conv_bn_6(x)\n",
    "        x = self.conv_bn_7(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa597f",
   "metadata": {},
   "source": [
    "#### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a35651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, batch_size):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def call(self, data, training=False): \n",
    "        # Method needed to be implemented for tensorflow reasons when using a custom data loader\n",
    "        pass\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = self.batch_size\n",
    "        #random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, 1, 1, self.latent_dim))\n",
    "        \n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        \n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1, 1, 1)), tf.zeros((batch_size, 1, 1, 1))], axis=0\n",
    "        )\n",
    "        \n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        #random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, 1, 1, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1, 1, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d3b01",
   "metadata": {},
   "source": [
    "**Callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "class SaveImagesCallback(Callback):\n",
    "    def __init__(self, logdir, latent_dim, save_freq, batch_size):\n",
    "        self.logdir = Path(f\"{logdir}/gan_image_output/{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\")\n",
    "        self.latent_dim = latent_dim\n",
    "        self.save_freq = save_freq\n",
    "        \n",
    "        self.logdir.mkdir(exist_ok=True, parents=True)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.fixed_noise = tf.random.normal([self.batch_size, 1, 1, self.latent_dim])\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs= None):\n",
    "        if epoch % self.save_freq == 0:\n",
    "            generator = self.model.generator\n",
    "            predictions = generator(self.fixed_noise, training=False)\n",
    "            \n",
    "            pred_index = np.random.choice(np.array(list(range(predictions.shape[0]))), size= predictions.shape[0])\n",
    "            predictions = np.array([predictions[x, :, :, :] for x in pred_index])\n",
    "            plt_shape = int(np.math.sqrt(predictions.shape[0]))\n",
    "            \n",
    "            fig = plt.figure(figsize=(8, 8))\n",
    "            for i in range(predictions.shape[0]):\n",
    "                plt.subplot(plt_shape, plt_shape, i+1)\n",
    "                plt.imshow(np.asarray(predictions[i, :, :, :] * 127.5 + 127.5, dtype= np.uint8))\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "            plt.savefig(f'{str(self.logdir)}/tf_image_at_epoch_{epoch:04d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS= 30000\n",
    "EPOCH_SAVE_FREQ = 30000\n",
    "LATENT_DIMENSION = 128\n",
    "IMAGE_SIZE = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses_cows_data = DataLoader(im_dir= \"dataset/Newdata/Train\", classification= False, output_dim= IMAGE_SIZE, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01360ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = 'gan-logdir/horses_cows/'\n",
    "isaveimg = SaveImagesCallback(logdir= logdir, latent_dim= LATENT_DIMENSION, save_freq= 100, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88472191",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(name= \"Discriminator\")\n",
    "generator = Generator(latent_dim= LATENT_DIMENSION, name= \"Generator\")\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=LATENT_DIMENSION, batch_size= BATCH_SIZE)\n",
    "\n",
    "optimizer_d = Adam(0.0001, 0.5)\n",
    "optimizer_g = Adam(0.0001, 0.5)\n",
    "\n",
    "gan.compile(d_optimizer= optimizer_d, g_optimizer= optimizer_g, loss_fn=BinaryCrossentropy())\n",
    "gan.fit(train_horses_cows_data, epochs=EPOCHS, callbacks= [isaveimg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828d67a",
   "metadata": {},
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "    def __init__(self, latent_dim, num_classes):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim, self.num_classes = latent_dim, num_classes\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.seq_model = Sequential(\n",
    "            [\n",
    "                Dense(16 * 16 * (self.latent_dim + self.num_classes)),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Reshape((16, 16, (self.latent_dim + self.num_classes))),\n",
    "                Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Conv2D(3, (7, 7), padding=\"same\", activation=\"tanh\"),    \n",
    "            ]\n",
    "        )\n",
    "        super(Generator, self).build(input_shape)\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        noise, label = input_tensor\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        \n",
    "        output = self.seq_model(model_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71887a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim, num_classes):\n",
    "\n",
    "    model = Sequential(\n",
    "    [\n",
    "        layers.InputLayer(latent_dim,),\n",
    "        Dense(16 * 16 * (latent_dim + num_classes)),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Reshape((16, 16, (latent_dim + num_classes))),\n",
    "        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Conv2D(3, (7, 7), padding=\"same\", activation=\"tanh\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(num_classes, latent_dim)(label))\n",
    "    model_input = multiply([noise, label_embedding])\n",
    "    img = model(model_input)\n",
    "\n",
    "    return Model([noise, label], img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "    def __init__(self, image_size, num_classes):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.img_shape, self.num_classes = image_size, num_classes\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.seq_model = Sequential(\n",
    "            [\n",
    "                Dense(512),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Dense(512),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Dropout(0.4),\n",
    "                Dense(512),\n",
    "                LeakyReLU(alpha=0.2),\n",
    "                Dropout(0.4),\n",
    "                Dense(1, activation='sigmoid')\n",
    "            ]\n",
    "        )\n",
    "        super(Discriminator, self).build(input_shape)\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        img, label = input_tensor\n",
    "        assert img.shape[1:] == self.img_shape, f\"Received input shape: {img.shape[1:]} does not match image shape: {self.img_shape} in Discriminator Call\"\n",
    "        \n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "        \n",
    "        output = self.seq_model(model_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feea104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(512, input_dim=np.prod(img_shape)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    label_embedding = Flatten()(Embedding(num_classes, np.prod(img_shape))(label))\n",
    "    flat_img = Flatten()(img)\n",
    "\n",
    "    model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "    validity = model(model_input)\n",
    "\n",
    "    return Model([img, label], validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CondGAN():\n",
    "    def __init__(self, image_size, num_classes, latent_dim, generator, discriminator):\n",
    "        # Input shape\n",
    "        self.img_rows, self.cols, self.channels = image_size\n",
    "        self.img_shape = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator(self.img_shape, self.num_classes)\n",
    "        \n",
    "        #self.discriminator.build(input_shape= [(None, *self.img_shape), (None, 1,)])\n",
    "        \n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = build_generator(latent_dim= self.latent_dim, num_classes= self.num_classes)\n",
    "        #self.generator.build(input_shape= [(None, self.latent_dim), (None, 1,)])\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding class of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def train(self, epochs, dataset, batch_size=128, sample_interval=50):\n",
    "        D_loss, G_loss, acc = [], [], []\n",
    "        # Load iterator dataset assuming DataLoader with one batch (full data)\n",
    "        X_train, y_train = next(iter(dataset))\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            D_loss.append(d_loss[0])\n",
    "            G_loss.append(g_loss)\n",
    "            acc.append(100*d_loss[1])\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 4\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        sampled_labels = np.array([[0], [0], [0], [0], [1], [1], [1], [1]]).reshape(-1, 1)\n",
    "\n",
    "        gen_imgs = self.generator.predict([noise, sampled_labels])\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = gen_imgs\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        for i in range(r):\n",
    "            if i == 0:\n",
    "                cnt = 0\n",
    "                title= \"Cow\"\n",
    "            elif i == 1:\n",
    "                cnt = 4\n",
    "                title= \"Horse\"\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(np.asarray(gen_imgs[cnt,:,:, :]* 127.5 + 127.5, dtype= np.uint8))\n",
    "                axs[i, j].set_title(title)\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (128, 128, 3)\n",
    "BATCH_SIZE = -1\n",
    "LATENT_DIM = 100\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses_cows = DataLoader(im_dir= \"dataset/Newdata/Train\", classification= False, output_dim= IMAGE_SIZE, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(LATENT_DIM, NUM_CLASSES)\n",
    "discriminator = Discriminator(IMAGE_SIZE, NUM_CLASSES)\n",
    "\n",
    "cgan = CondGAN(image_size= IMAGE_SIZE, num_classes= NUM_CLASSES, latent_dim= LATENT_DIM, generator= generator, discriminator= discriminator)\n",
    "cgan.train(epochs=40000, dataset= train_horses_cows, batch_size=4, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fdead4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab12adf",
   "metadata": {},
   "source": [
    "### Generating 1000 Images for Both Cows and Horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ede3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_of_images = [250, 500, 1000]\n",
    "\n",
    "noise_labels = {}\n",
    "for no_im in nb_of_images:\n",
    "    noise_labels[f\"noise_{no_im}\"] = tf.random.normal(shape= (no_im, 100))\n",
    "    noise_labels[f\"labels_{no_im}\"] = np.random.randint(low= 0, high= 2, size= (no_im, 1)).reshape(-1, 1)\n",
    "\n",
    "generated_cows_horses_images_250 = np.asarray(cgan.generator.predict([noise_labels[\"noise_250\"], noise_labels[\"labels_250\"]]) * 127.5 + 127.5, dtype= np.uint8)\n",
    "generated_cows_horses_images_500 =  np.asarray(cgan.generator.predict([noise_labels[\"noise_500\"], noise_labels[\"labels_500\"]]) * 127.5 + 127.5, dtype= np.uint8)\n",
    "generated_cows_horses_images_1000 =  np.asarray(cgan.generator.predict([noise_labels[\"noise_1000\"], noise_labels[\"labels_1000\"]]) * 127.5 + 127.5, dtype= np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbd32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_250 = (np.asarray(generated_cows_horses_images_250, dtype= np.float32), np.asarray(noise_labels[\"labels_250\"], dtype= np.int32))\n",
    "generated_data_500 = (np.asarray(generated_cows_horses_images_500, dtype= np.float32), np.asarray(noise_labels[\"labels_500\"], dtype= np.int32))\n",
    "generated_data_1000 = (np.asarray(generated_cows_horses_images_1000, dtype= np.float32), np.asarray(noise_labels[\"labels_1000\"], dtype= np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_batch = [data for i, data in enumerate(generated_data_250[0]) if generated_data_250[1][i] == 1]\n",
    "cow_batch = [data for i, data in enumerate(generated_data_250[0]) if generated_data_250[1][i] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdcf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_horse = np.random.choice(range(len(horse_batch)), size= 4, replace= False)\n",
    "random_cow = np.random.choice(range(len(cow_batch)-1), size= 4, replace= False)\n",
    "random_horse, random_cow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cow_images, horse_images = [np.asarray(cow_batch[i], dtype= np.uint8) for i in random_cow], [np.asarray(horse_batch[i], dtype= np.uint8) for i in random_horse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10., 10.), constrained_layout=True)\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, im in zip(grid, [*cow_images, *horse_images]):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)\n",
    "print(\"\\tGenerated Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c505b",
   "metadata": {},
   "source": [
    "### Appending To Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b92481",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses_cows_classification = tf.keras.preprocessing.image_dataset_from_directory(directory= \"dataset/Newdata/Train\",\n",
    "                                                                                      batch_size= 16, image_size= (128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horses_cows_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_dataset_250 = tf.data.Dataset.from_tensor_slices(generated_data_250).batch(batch_size= 16)\n",
    "generated_dataset_500 = tf.data.Dataset.from_tensor_slices(generated_data_500).batch(batch_size= 16)\n",
    "generated_dataset_1000 = tf.data.Dataset.from_tensor_slices(generated_data_1000).batch(batch_size= 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset_250 = train_horses_cows_classification.concatenate(generated_dataset_250).shuffle(buffer_size= len(generated_dataset_250))\n",
    "combined_dataset_500 = train_horses_cows_classification.concatenate(generated_dataset_500).shuffle(buffer_size= len(generated_dataset_500))\n",
    "combined_dataset_1000 = train_horses_cows_classification.concatenate(generated_dataset_1000).shuffle(buffer_size= len(generated_dataset_1000))\n",
    "\n",
    "val_horses_cows = DataLoader(im_dir= \"dataset/Newdata/Test\", classification= True, output_dim= (128, 128, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83111c2c",
   "metadata": {},
   "source": [
    "### Classification Re-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS= 50\n",
    "BATCH_SIZE= 16\n",
    "IMAGE_SIZE= (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horses_cows_classifier_gen = Classifier(name= \"Horses_vs_Cows_Classifier_with_Gen_Data\")\n",
    "horses_cows_classifier_gen.build(input_shape= (None, *IMAGE_SIZE))\n",
    "\n",
    "horses_cows_classifier_gen.summary()\n",
    "horses_cows_classifier_gen.compile(optimizer= Adam(0.001), loss= BinaryCrossentropy(), metrics= [BinaryAccuracy(), Recall(), Precision(), MSE])\n",
    "# combined_dataset_250, combined_dataset_500, combined_dataset_1000\n",
    "model_data = horses_cows_classifier_gen.fit(combined_dataset_1000, validation_data= val_horses_cows_classification, epochs= EPOCHS, workers= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13088d76",
   "metadata": {},
   "source": [
    "### Re-training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53611f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics_classification(horses_cows_classifier_gen.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12381e6",
   "metadata": {},
   "source": [
    "## Neural Style Transfer and Cycle GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory= \"dataset/Newdata/Train\").unbatch()\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(directory= \"dataset/Newdata/Train\").unbatch()\n",
    "\n",
    "train_cows = train_dataset.filter(lambda img, label: label == 0).map(lambda img, label: img)\n",
    "train_horses = train_dataset.filter(lambda img, label: label == 1).map(lambda img, label: img)\n",
    "\n",
    "test_cows = test_dataset.filter(lambda img, label: label == 0).map(lambda img, label: img)\n",
    "test_horses = test_dataset.filter(lambda img, label: label == 1).map(lambda img, label: img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a44f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the standard image size.\n",
    "orig_img_size = (256, 256)\n",
    "# Size of the random crops to be used during training.\n",
    "input_img_size = (200, 200, 3)\n",
    "# Weights initializer for the layers.\n",
    "kernel_init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "# Gamma initializer for instance normalization.\n",
    "gamma_init = RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "buffer_size = 256\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    # Map values in the range [-1, 1]\n",
    "    return (img / 127.5) - 1.0\n",
    "\n",
    "\n",
    "def preprocess_train_image(img):\n",
    "    # Random flip\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    # Resize to the original size first\n",
    "    img = tf.image.resize(img, [*orig_img_size])\n",
    "    # Random crop to 256X256\n",
    "    img = tf.image.random_crop(img, size=[*input_img_size])\n",
    "    # Normalize the pixel values in the range [-1, 1]\n",
    "    img = normalize_img(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_test_image(img):\n",
    "    # Only resizing and normalization for the test images.\n",
    "    img = tf.image.resize(img, [input_img_size[0], input_img_size[1]])\n",
    "    img = normalize_img(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing operations to the training data\n",
    "train_horses = (\n",
    "    train_horses.map(preprocess_train_image)\n",
    "    .cache()\n",
    "    .shuffle(buffer_size)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "train_cows = (\n",
    "    train_cows.map(preprocess_train_image)\n",
    "    .cache()\n",
    "    .shuffle(buffer_size)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "# Apply the preprocessing operations to the test data\n",
    "test_horses = (\n",
    "    test_horses.map(preprocess_test_image)\n",
    "    .cache()\n",
    "    .shuffle(buffer_size)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "test_cows = (\n",
    "    test_cows.map(preprocess_test_image)\n",
    "    .cache()\n",
    "    .shuffle(buffer_size)\n",
    "    .batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37205860",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 2, figsize=(10, 15))\n",
    "for i, samples in enumerate(zip(train_horses.take(4), train_cows.take(4))):\n",
    "    horse = (((samples[0][0] * 127.5) + 127.5).numpy()).astype(np.uint8)\n",
    "    cow = (((samples[1][0] * 127.5) + 127.5).numpy()).astype(np.uint8)\n",
    "    ax[i, 0].imshow(horse)\n",
    "    ax[i, 1].imshow(cow)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22245f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding2D(Layer):\n",
    "\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        padding_width, padding_height = self.padding\n",
    "        padding_tensor = [\n",
    "            [0, 0],\n",
    "            [padding_height, padding_height],\n",
    "            [padding_width, padding_width],\n",
    "            [0, 0],\n",
    "        ]\n",
    "        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n",
    "\n",
    "\n",
    "def residual_block(\n",
    "    x,\n",
    "    activation,\n",
    "    kernel_initializer=kernel_init,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"valid\",\n",
    "    gamma_initializer=gamma_init,\n",
    "    use_bias=False,\n",
    "):\n",
    "    dim = x.shape[-1]\n",
    "    input_tensor = x\n",
    "\n",
    "    x = ReflectionPadding2D()(input_tensor)\n",
    "    x = layers.Conv2D(\n",
    "        dim,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    x = activation(x)\n",
    "\n",
    "    x = ReflectionPadding2D()(x)\n",
    "    x = layers.Conv2D(\n",
    "        dim,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    x = layers.add([input_tensor, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def downsample(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_initializer=kernel_init,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(2, 2),\n",
    "    padding=\"same\",\n",
    "    gamma_initializer=gamma_init,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsample(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(2, 2),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=kernel_init,\n",
    "    gamma_initializer=gamma_init,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71de351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_generator(\n",
    "    filters=64,\n",
    "    num_downsampling_blocks=2,\n",
    "    num_residual_blocks=9,\n",
    "    num_upsample_blocks=2,\n",
    "    gamma_initializer=gamma_init,\n",
    "    name=None,\n",
    "):\n",
    "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
    "    x = ReflectionPadding2D(padding=(3, 3))(img_input)\n",
    "    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(\n",
    "        x\n",
    "    )\n",
    "    x = tfa.layers.InstanceNormalization(gamma_initializer=gamma_initializer)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # Downsampling\n",
    "    for _ in range(num_downsampling_blocks):\n",
    "        filters *= 2\n",
    "        x = downsample(x, filters=filters, activation=layers.Activation(\"relu\"))\n",
    "\n",
    "    # Residual blocks\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, activation=layers.Activation(\"relu\"))\n",
    "\n",
    "    # Upsampling\n",
    "    for _ in range(num_upsample_blocks):\n",
    "        filters //= 2\n",
    "        x = upsample(x, filters, activation=layers.Activation(\"relu\"))\n",
    "\n",
    "    # Final block\n",
    "    x = ReflectionPadding2D(padding=(3, 3))(x)\n",
    "    x = layers.Conv2D(3, (7, 7), padding=\"valid\")(x)\n",
    "    x = layers.Activation(\"tanh\")(x)\n",
    "\n",
    "    model = Model(img_input, x, name=name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25667016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(\n",
    "    filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None\n",
    "):\n",
    "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        (4, 4),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=kernel_initializer,\n",
    "    )(img_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    num_filters = filters\n",
    "    for num_downsample_block in range(3):\n",
    "        num_filters *= 2\n",
    "        if num_downsample_block < 2:\n",
    "            x = downsample(\n",
    "                x,\n",
    "                filters=num_filters,\n",
    "                activation=layers.LeakyReLU(0.2),\n",
    "                kernel_size=(4, 4),\n",
    "                strides=(2, 2),\n",
    "            )\n",
    "        else:\n",
    "            x = downsample(\n",
    "                x,\n",
    "                filters=num_filters,\n",
    "                activation=layers.LeakyReLU(0.2),\n",
    "                kernel_size=(4, 4),\n",
    "                strides=(1, 1),\n",
    "            )\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        1, (4, 4), strides=(1, 1), padding=\"same\", kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "\n",
    "    model = Model(inputs=img_input, outputs=x, name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Get the generators\n",
    "gen_G = get_resnet_generator(name=\"generator_G\")\n",
    "gen_F = get_resnet_generator(name=\"generator_F\")\n",
    "\n",
    "# Get the discriminators\n",
    "disc_X = get_discriminator(name=\"discriminator_X\")\n",
    "disc_Y = get_discriminator(name=\"discriminator_Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7ad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_G,\n",
    "        generator_F,\n",
    "        discriminator_X,\n",
    "        discriminator_Y,\n",
    "        lambda_cycle=10.0,\n",
    "        lambda_identity=0.5,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.gen_G = generator_G\n",
    "        self.gen_F = generator_F\n",
    "        self.disc_X = discriminator_X\n",
    "        self.disc_Y = discriminator_Y\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        self.lambda_identity = lambda_identity\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        gen_G_optimizer,\n",
    "        gen_F_optimizer,\n",
    "        disc_X_optimizer,\n",
    "        disc_Y_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.gen_G_optimizer = gen_G_optimizer\n",
    "        self.gen_F_optimizer = gen_F_optimizer\n",
    "        self.disc_X_optimizer = disc_X_optimizer\n",
    "        self.disc_Y_optimizer = disc_Y_optimizer\n",
    "        self.generator_loss_fn = gen_loss_fn\n",
    "        self.discriminator_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = MeanAbsoluteError()\n",
    "        self.identity_loss_fn = MeanAbsoluteError()\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        # x is Horse and y is Cow\n",
    "        real_x, real_y = batch_data\n",
    "\n",
    "        # For CycleGAN, we need to calculate different\n",
    "        # kinds of losses for the generators and discriminators.\n",
    "        # We will perform the following steps here:\n",
    "        #\n",
    "        # 1. Pass real images through the generators and get the generated images\n",
    "        # 2. Pass the generated images back to the generators to check if we\n",
    "        #    we can predict the original image from the generated image.\n",
    "        # 3. Do an identity mapping of the real images using the generators.\n",
    "        # 4. Pass the generated images in 1) to the corresponding discriminators.\n",
    "        # 5. Calculate the generators total loss (adverserial + cycle + identity)\n",
    "        # 6. Calculate the discriminators loss\n",
    "        # 7. Update the weights of the generators\n",
    "        # 8. Update the weights of the discriminators\n",
    "        # 9. Return the losses in a dictionary\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Horse to fake Cow\n",
    "            fake_y = self.gen_G(real_x, training=True)\n",
    "            # Cow to fake horse -> y2x\n",
    "            fake_x = self.gen_F(real_y, training=True)\n",
    "\n",
    "            # Cycle (Horse to fake Cow to fake horse): x -> y -> x\n",
    "            cycled_x = self.gen_F(fake_y, training=True)\n",
    "            # Cycle (Cow to fake horse to fake Cow) y -> x -> y\n",
    "            cycled_y = self.gen_G(fake_x, training=True)\n",
    "\n",
    "            # Identity mapping\n",
    "            same_x = self.gen_F(real_x, training=True)\n",
    "            same_y = self.gen_G(real_y, training=True)\n",
    "\n",
    "            # Discriminator output\n",
    "            disc_real_x = self.disc_X(real_x, training=True)\n",
    "            disc_fake_x = self.disc_X(fake_x, training=True)\n",
    "\n",
    "            disc_real_y = self.disc_Y(real_y, training=True)\n",
    "            disc_fake_y = self.disc_Y(fake_y, training=True)\n",
    "\n",
    "            # Generator adverserial loss\n",
    "            gen_G_loss = self.generator_loss_fn(disc_fake_y)\n",
    "            gen_F_loss = self.generator_loss_fn(disc_fake_x)\n",
    "\n",
    "            # Generator cycle loss\n",
    "            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle\n",
    "            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle\n",
    "\n",
    "            # Generator identity loss\n",
    "            id_loss_G = (\n",
    "                self.identity_loss_fn(real_y, same_y)\n",
    "                * self.lambda_cycle\n",
    "                * self.lambda_identity\n",
    "            )\n",
    "            id_loss_F = (\n",
    "                self.identity_loss_fn(real_x, same_x)\n",
    "                * self.lambda_cycle\n",
    "                * self.lambda_identity\n",
    "            )\n",
    "\n",
    "            # Total generator loss\n",
    "            total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G\n",
    "            total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F\n",
    "\n",
    "            # Discriminator loss\n",
    "            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)\n",
    "            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)\n",
    "\n",
    "        # Get the gradients for the generators\n",
    "        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n",
    "        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n",
    "\n",
    "        # Get the gradients for the discriminators\n",
    "        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n",
    "        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n",
    "\n",
    "        # Update the weights of the generators\n",
    "        self.gen_G_optimizer.apply_gradients(\n",
    "            zip(grads_G, self.gen_G.trainable_variables)\n",
    "        )\n",
    "        self.gen_F_optimizer.apply_gradients(\n",
    "            zip(grads_F, self.gen_F.trainable_variables)\n",
    "        )\n",
    "\n",
    "        # Update the weights of the discriminators\n",
    "        self.disc_X_optimizer.apply_gradients(\n",
    "            zip(disc_X_grads, self.disc_X.trainable_variables)\n",
    "        )\n",
    "        self.disc_Y_optimizer.apply_gradients(\n",
    "            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"G_loss\": total_loss_G,\n",
    "            \"F_loss\": total_loss_F,\n",
    "            \"D_X_loss\": disc_X_loss,\n",
    "            \"D_Y_loss\": disc_Y_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(Callback):\n",
    "    \"\"\"A callback to generate and save images after each epoch\"\"\"\n",
    "\n",
    "    def __init__(self, num_img=4):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _, ax = plt.subplots(4, 2, figsize=(12, 12))\n",
    "        for i, img in enumerate(test_horses.take(self.num_img)):\n",
    "            prediction = self.model.gen_G(img)[0].numpy()\n",
    "            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "            img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "            ax[i, 0].imshow(img)\n",
    "            ax[i, 1].imshow(prediction)\n",
    "            ax[i, 0].set_title(\"Input image\")\n",
    "            ax[i, 1].set_title(\"Translated image\")\n",
    "            ax[i, 0].axis(\"off\")\n",
    "            ax[i, 1].axis(\"off\")\n",
    "\n",
    "            prediction = tf.keras.preprocessing.image.array_to_img(prediction)\n",
    "            prediction.save(\n",
    "                \"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch + 1)\n",
    "            )\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function for evaluating adversarial loss\n",
    "adv_loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "# Define the loss function for the generators\n",
    "def generator_loss_fn(fake):\n",
    "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
    "    return fake_loss\n",
    "\n",
    "\n",
    "# Define the loss function for the discriminators\n",
    "def discriminator_loss_fn(real, fake):\n",
    "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
    "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
    "    return (real_loss + fake_loss) * 0.5\n",
    "\n",
    "\n",
    "# Create cycle gan model\n",
    "cycle_gan_model = CycleGan(\n",
    "    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "cycle_gan_model.compile(\n",
    "    gen_G_optimizer=Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    gen_F_optimizer=Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    disc_X_optimizer=Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    disc_Y_optimizer=Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "    gen_loss_fn=generator_loss_fn,\n",
    "    disc_loss_fn=discriminator_loss_fn,\n",
    ")\n",
    "# Callbacks\n",
    "plotter = GANMonitor()\n",
    "\n",
    "cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((train_horses, train_cows)),\n",
    "    epochs=50,\n",
    "    callbacks=[plotter],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 2, figsize=(10, 15))\n",
    "for i, img in enumerate(test_horses.take(4)):\n",
    "    prediction = cycle_gan_model.gen_G(img, training=False)[0].numpy()\n",
    "    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
    "\n",
    "    ax[i, 0].imshow(img)\n",
    "    ax[i, 1].imshow(prediction)\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 0].set_title(\"Input image\")\n",
    "    ax[i, 1].set_title(\"Translated image\")\n",
    "    ax[i, 0].axis(\"off\")\n",
    "    ax[i, 1].axis(\"off\")\n",
    "\n",
    "    prediction = tf.keras.preprocessing.image.array_to_img(prediction)\n",
    "    prediction.save(\"predicted_img_{i}.png\".format(i=i))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
